{
  "cells": [
    {
      "metadata": {
        "id": "7dfb706ccc381938"
      },
      "cell_type": "markdown",
      "source": [
        "# MOQ Price Analysis for Wholesale B2B Businesses"
      ],
      "id": "7dfb706ccc381938"
    },
    {
      "metadata": {
        "id": "afd944d1791461e8"
      },
      "cell_type": "markdown",
      "source": [
        "## importing libraries"
      ],
      "id": "afd944d1791461e8"
    },
    {
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:37.046515Z",
          "start_time": "2025-12-22T09:46:36.932993Z"
        },
        "id": "755aac1dae3c4f59"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "755aac1dae3c4f59",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "deba2e2386bf4ab6"
      },
      "cell_type": "markdown",
      "source": [
        "## extracting the dataset"
      ],
      "id": "deba2e2386bf4ab6"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:42.267164Z",
          "start_time": "2025-12-22T09:46:37.141354Z"
        },
        "id": "7503da627f76c127"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('online_retail_II.csv')\n",
        "print(df.dtypes)"
      ],
      "id": "7503da627f76c127",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "99aa64d8ef0c127f"
      },
      "cell_type": "markdown",
      "source": [
        "## analysing data quality"
      ],
      "id": "99aa64d8ef0c127f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:46.069386Z",
          "start_time": "2025-12-22T09:46:44.908133Z"
        },
        "id": "9995591c7db6cfdd"
      },
      "cell_type": "code",
      "source": [
        "# finding missing data\n",
        "missing_data = pd.DataFrame({\n",
        "    'columns': df.columns,\n",
        "    'null count': df.isnull().sum(),\n",
        "    'null percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
        "})\n",
        "\n",
        "print(missing_data)"
      ],
      "id": "9995591c7db6cfdd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:47.174009Z",
          "start_time": "2025-12-22T09:46:46.134126Z"
        },
        "id": "a4404918309355d"
      },
      "cell_type": "code",
      "source": [
        "# finding unique data\n",
        "for col in df.columns:\n",
        "    print(f'{col}: {df[col].nunique()}')"
      ],
      "id": "a4404918309355d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:47.333223Z",
          "start_time": "2025-12-22T09:46:47.274013Z"
        },
        "id": "c41fe3345a1c9eb9"
      },
      "cell_type": "code",
      "source": [
        "# getting a sample of the dataset\n",
        "df.head(10)"
      ],
      "id": "c41fe3345a1c9eb9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:48.876641Z",
          "start_time": "2025-12-22T09:46:47.648057Z"
        },
        "id": "4683b6a37e1bf064"
      },
      "cell_type": "code",
      "source": [
        "# descriptive statistics from the dataset\n",
        "df.describe()"
      ],
      "id": "4683b6a37e1bf064",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d604a84619141739"
      },
      "cell_type": "markdown",
      "source": [
        "## identifying and documenting problems"
      ],
      "id": "d604a84619141739"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:50.748517Z",
          "start_time": "2025-12-22T09:46:50.652168Z"
        },
        "id": "395455ed06bddc91"
      },
      "cell_type": "code",
      "source": [
        "# negative numbers in quantity\n",
        "negative_qty = df[df['Quantity'] < 0]\n",
        "print(negative_qty.head(10))"
      ],
      "id": "395455ed06bddc91",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:51.165604Z",
          "start_time": "2025-12-22T09:46:51.129776Z"
        },
        "id": "c426ef7b64874006"
      },
      "cell_type": "code",
      "source": [
        "# zero or negative prices in price\n",
        "zero_price = df[df['Price'] <= 0]\n",
        "print(zero_price.head(10))"
      ],
      "id": "c426ef7b64874006",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:54.236249Z",
          "start_time": "2025-12-22T09:46:51.619367Z"
        },
        "id": "e89b754ee2787a1b"
      },
      "cell_type": "code",
      "source": [
        "# special codes (non-products)\n",
        "special_codes = df[df['StockCode'].str.contains('^[A-Z]+$', na=False, regex=True)]\n",
        "print(special_codes['StockCode'].value_counts().head(10))"
      ],
      "id": "e89b754ee2787a1b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:54.490723Z",
          "start_time": "2025-12-22T09:46:54.371871Z"
        },
        "id": "a1e7b420edb69550"
      },
      "cell_type": "code",
      "source": [
        "# missing customer id\n",
        "no_customer = df[df['Customer ID'].isnull()]\n",
        "print(no_customer.head(10))"
      ],
      "id": "a1e7b420edb69550",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:54.701610Z",
          "start_time": "2025-12-22T09:46:54.583917Z"
        },
        "id": "e848549acc8ec1da"
      },
      "cell_type": "code",
      "source": [
        "# missing descriptions\n",
        "no_desc = df[df['Description'].isnull()]\n",
        "print(no_desc.head(10))"
      ],
      "id": "e848549acc8ec1da",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:54.855920Z",
          "start_time": "2025-12-22T09:46:54.767854Z"
        },
        "id": "830396b8d25ef210"
      },
      "cell_type": "code",
      "source": [
        "# finding outliers in quantity\n",
        "print(f\"minimun quantity: {df['Quantity'].min()}\")\n",
        "print(f\"maximun quantity: {df['Quantity'].max()}\")\n",
        "print(f\"mean quantity: {df['Quantity'].mean()}\")\n",
        "print(f\"99 percentile quantity: {df['Quantity'].quantile(0.99)}\")\n",
        "print(f\"99.9 percentile quantity: {df['Quantity'].quantile(0.999)}\")"
      ],
      "id": "830396b8d25ef210",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d08cdb7808143216"
      },
      "cell_type": "markdown",
      "source": [
        "## cleaning the dataset"
      ],
      "id": "d08cdb7808143216"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:55.042403Z",
          "start_time": "2025-12-22T09:46:54.931621Z"
        },
        "id": "1d69be08474556ad"
      },
      "cell_type": "code",
      "source": [
        "# getting a copy for the process\n",
        "df_clean = df.copy()\n",
        "print(f\"number of initial records: {len(df_clean)}\")"
      ],
      "id": "1d69be08474556ad",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:55.166530Z",
          "start_time": "2025-12-22T09:46:55.155877Z"
        },
        "id": "10c64aa1e0cc3490"
      },
      "cell_type": "code",
      "source": [
        "# cleaning report\n",
        "cleaning_report = {\n",
        "    'step': [],\n",
        "    'description': [],\n",
        "    'removed count': [],\n",
        "    'remaining count': []\n",
        "}\n",
        "\n",
        "def add_cleaning_step(step_name, description, removed_count, remaining_count):\n",
        "    cleaning_report['step'].append(step_name)\n",
        "    cleaning_report['description'].append(description)\n",
        "    cleaning_report['removed count'].append(removed_count)\n",
        "    cleaning_report['remaining count'].append(remaining_count)"
      ],
      "id": "10c64aa1e0cc3490",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "90191647bd539280"
      },
      "cell_type": "markdown",
      "source": [
        "### step 1: removing the returns"
      ],
      "id": "90191647bd539280"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:55.595479Z",
          "start_time": "2025-12-22T09:46:55.204279Z"
        },
        "id": "f62b6bbc1bfad2ec"
      },
      "cell_type": "code",
      "source": [
        "# counting before removing\n",
        "before_q = len(df_clean)\n",
        "\n",
        "# filtering\n",
        "df_clean = df_clean[df_clean['Quantity'] > 0]\n",
        "\n",
        "# counting after removing\n",
        "after_q = len(df_clean)\n",
        "removed_q = before_q - after_q\n",
        "\n",
        "print(f\"removed: {removed_q} records\")\n",
        "print(f\"remaining: {after_q} records\")\n",
        "\n",
        "# adding to report\n",
        "add_cleaning_step('step1', 'removed negative quantities', removed_q, after_q)"
      ],
      "id": "f62b6bbc1bfad2ec",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ae4d73fb2e7d66e"
      },
      "cell_type": "markdown",
      "source": [
        "### step2: removing invalid prices"
      ],
      "id": "ae4d73fb2e7d66e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:55.872795Z",
          "start_time": "2025-12-22T09:46:55.622485Z"
        },
        "id": "32dcbd3e6565c07b"
      },
      "cell_type": "code",
      "source": [
        "before_p = len(df_clean)\n",
        "\n",
        "# removing negative or zero prices\n",
        "df_clean = df_clean[df_clean['Price'] > 0]\n",
        "\n",
        "after_p = len(df_clean)\n",
        "removed_p = before_p - after_p\n",
        "\n",
        "print(f\"removed: {removed_p} records\")\n",
        "print(f\"remaining: {after_p} records\")\n",
        "\n",
        "add_cleaning_step('step2', 'removed negative and zero prices', removed_p, after_p)"
      ],
      "id": "32dcbd3e6565c07b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "18865f6984443625"
      },
      "cell_type": "markdown",
      "source": [
        "### step3: removing non-product stock codes"
      ],
      "id": "18865f6984443625"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:58.325295Z",
          "start_time": "2025-12-22T09:46:55.960301Z"
        },
        "id": "516c830200d32054"
      },
      "cell_type": "code",
      "source": [
        "before_s = len(df_clean)\n",
        "\n",
        "# identifying special code patterns\n",
        "special_patterns = ['POST', 'D', 'DOT', 'M', 'BANK CHARGES', 'PADS', 'C2', 'CRUK', 'AMAZONFEE']\n",
        "\n",
        "# removing stock codes with special patterns\n",
        "df_clean = df_clean[~(df_clean['StockCode'].isin(special_patterns))]\n",
        "\n",
        "# removing stock codes with one worded codes\n",
        "df_clean = df_clean[~(df_clean['StockCode'].str.match('^[A-Z]$', na=False))]\n",
        "\n",
        "after_s = len(df_clean)\n",
        "removed_s = before_s - after_s\n",
        "\n",
        "print(f\"removed: {removed_s} records\")\n",
        "print(f\"remaining: {after_s} records\")\n",
        "\n",
        "add_cleaning_step('step3', 'removed non-product stock codes', removed_s, after_s)"
      ],
      "id": "516c830200d32054",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "1722e4d12081e9a6"
      },
      "cell_type": "markdown",
      "source": [
        "### step4: removing missing descriptions"
      ],
      "id": "1722e4d12081e9a6"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:58.782938Z",
          "start_time": "2025-12-22T09:46:58.427377Z"
        },
        "id": "cba5d768b8b255aa"
      },
      "cell_type": "code",
      "source": [
        "before_d = len(df_clean)\n",
        "\n",
        "df_clean = df_clean[df_clean['Description'].notna()]\n",
        "\n",
        "after_d = len(df_clean)\n",
        "removed_d = before_d - after_d\n",
        "\n",
        "print(f\"removed: {removed_d} records\")\n",
        "print(f\"remaining: {after_d} records\")\n",
        "\n",
        "add_cleaning_step('step4', 'removed missing descriptions', removed_d, after_d)"
      ],
      "id": "cba5d768b8b255aa",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8ca4fb18f7f732b9"
      },
      "cell_type": "markdown",
      "source": [
        "### step5: removing no customer id values"
      ],
      "id": "8ca4fb18f7f732b9"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:59.082562Z",
          "start_time": "2025-12-22T09:46:58.860898Z"
        },
        "id": "b7ce4f7cc47d1197"
      },
      "cell_type": "code",
      "source": [
        "# finding records with no customer ids\n",
        "no_customer = df_clean[df_clean['Customer ID'].isna()]\n",
        "\n",
        "before_c = len(df_clean)\n",
        "\n",
        "# removing no customer id records for moq strategy\n",
        "df_clean = df_clean[df_clean['Customer ID'].notna()]\n",
        "\n",
        "after_c = len(df_clean)\n",
        "removed_c = before_c - after_c\n",
        "\n",
        "print(f\"removed: {removed_c} records\")\n",
        "print(f\"remaining: {after_c} records\")\n",
        "\n",
        "add_cleaning_step('step5', 'removed records with no customer id', removed_c, after_c)"
      ],
      "id": "b7ce4f7cc47d1197",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "2f7a7c565ddcf0da"
      },
      "cell_type": "markdown",
      "source": [
        "### step6: managing outliers in quantity with IQR method"
      ],
      "id": "2f7a7c565ddcf0da"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:59.207613Z",
          "start_time": "2025-12-22T09:46:59.142870Z"
        },
        "id": "a813440d3da8d568"
      },
      "cell_type": "code",
      "source": [
        "# calculating IQR\n",
        "Q1 = df_clean['Quantity'].quantile(0.25)\n",
        "Q3 = df_clean['Quantity'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# defining bounds with (3*IQR) for extreme outliers\n",
        "lower_bound = Q1 - 3 * IQR\n",
        "upper_bound = Q3 + 3 * IQR\n",
        "\n",
        "print('quantity stats')\n",
        "print(f'Q1: {Q1}')\n",
        "print(f'Q3: {Q3}')\n",
        "print(f'IQR: {IQR}')\n",
        "print(f'accepted bounds are from {lower_bound} to {upper_bound}')"
      ],
      "id": "a813440d3da8d568",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:46:59.552636Z",
          "start_time": "2025-12-22T09:46:59.282296Z"
        },
        "id": "5112163e0456dc08"
      },
      "cell_type": "code",
      "source": [
        "# identifying outliers\n",
        "outliers = df_clean[(df_clean['Quantity'] < lower_bound) | (df_clean['Quantity'] > upper_bound)]\n",
        "\n",
        "before_o = len(df_clean)\n",
        "\n",
        "# note: order quantities more than 10000 are considered extreme and are removed\n",
        "df_clean = df_clean[df_clean['Quantity'] <= 10000]\n",
        "\n",
        "after_o = len(df_clean)\n",
        "removed_o = before_o - after_o\n",
        "\n",
        "print(f\"removed: {removed_o} records\")\n",
        "print(f\"remaining: {after_o} records\")\n",
        "\n",
        "add_cleaning_step('step6', 'removed outliers with IQR method', removed_o, after_o)"
      ],
      "id": "5112163e0456dc08",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "77d56caee0c31625"
      },
      "cell_type": "markdown",
      "source": [
        "### step7: cleaning and standardizing descriptions"
      ],
      "id": "77d56caee0c31625"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:09.336873Z",
          "start_time": "2025-12-22T09:46:59.706643Z"
        },
        "id": "4f0b13bf78bd66cd"
      },
      "cell_type": "code",
      "source": [
        "# making all texts uppercase\n",
        "df_clean['Description'] = df_clean['Description'].str.upper()\n",
        "\n",
        "# removing extra spaces\n",
        "df_clean['Description'] = df_clean['Description'].str.strip()\n",
        "\n",
        "# removing extra special characters\n",
        "df_clean['Description'] = df_clean['Description'].str.replace('[^\\w\\s]', ' ', regex=True)\n",
        "\n",
        "# removing extra spaces\n",
        "df_clean['Description'] = df_clean['Description'].str.replace('\\s+', ' ', regex=True)\n",
        "\n",
        "add_cleaning_step('step7', 'standardized descriptions', 0, after_d)"
      ],
      "id": "4f0b13bf78bd66cd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8b617a528c178ea"
      },
      "cell_type": "markdown",
      "source": [
        "### step8: standardizing datetimes"
      ],
      "id": "8b617a528c178ea"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:11.682273Z",
          "start_time": "2025-12-22T09:47:09.502321Z"
        },
        "id": "ddcb56e3db38e423"
      },
      "cell_type": "code",
      "source": [
        "# checking datetime\n",
        "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
        "\n",
        "# extracting time from datetime\n",
        "df_clean['Year'] = df_clean['InvoiceDate'].dt.year\n",
        "df_clean['Month'] = df_clean['InvoiceDate'].dt.month\n",
        "df_clean['Day'] = df_clean['InvoiceDate'].dt.day\n",
        "df_clean['DayOfWeek'] = df_clean['InvoiceDate'].dt.dayofweek\n",
        "df_clean['Hour'] = df_clean['InvoiceDate'].dt.hour\n",
        "\n",
        "# making a quarter\n",
        "df_clean['Quarter'] = df_clean['InvoiceDate'].dt.quarter\n",
        "\n",
        "# making a season\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'Winter'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'Spring'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'Summer'\n",
        "    else:\n",
        "        return 'Autumn'\n",
        "\n",
        "df_clean['Season'] = df_clean['Month'].apply(get_season)\n",
        "\n",
        "# invoice date ranges\n",
        "print(f\"invoice date range is from {df_clean['InvoiceDate'].min()} to {df_clean['InvoiceDate'].max()}\")\n",
        "\n",
        "add_cleaning_step('step8', 'fixed datetime in invoice dates', 0, 0)"
      ],
      "id": "ddcb56e3db38e423",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "37e379cedb7ed94f"
      },
      "cell_type": "markdown",
      "source": [
        "### step9: correcting data types"
      ],
      "id": "37e379cedb7ed94f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:12.132823Z",
          "start_time": "2025-12-22T09:47:11.946692Z"
        },
        "id": "4c1221455942b1ee"
      },
      "cell_type": "code",
      "source": [
        "# turning all customer ids to int\n",
        "df_clean['Customer ID'] = df_clean['Customer ID'].astype(int)\n",
        "\n",
        "# turning stock codes to strings\n",
        "df_clean['StockCode'] = df_clean['StockCode'].astype(str)\n",
        "\n",
        "# turning invoices to strings\n",
        "df_clean['Invoice'] = df_clean['Invoice'].astype(str)\n",
        "\n",
        "# making price float and quantity int\n",
        "df_clean['Quantity'] = df_clean['Quantity'].astype(int)\n",
        "df_clean['Price'] = df_clean['Price'].astype(float)\n",
        "\n",
        "add_cleaning_step('step9', 'corrected data types', 0, 0)"
      ],
      "id": "4c1221455942b1ee",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ac11528b6055bd9d"
      },
      "cell_type": "markdown",
      "source": [
        "### step10: generating the total price column"
      ],
      "id": "ac11528b6055bd9d"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:12.248761Z",
          "start_time": "2025-12-22T09:47:12.206986Z"
        },
        "id": "dd3c485225c98fd6"
      },
      "cell_type": "code",
      "source": [
        "df_clean['TotalPrice'] = (df_clean['Quantity'] * df_clean['Price']).round(2)\n",
        "df_clean['TotalPrice']"
      ],
      "id": "dd3c485225c98fd6",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4ea4e73464993045"
      },
      "cell_type": "markdown",
      "source": [
        "### step11: removing duplicates (if existing)"
      ],
      "id": "4ea4e73464993045"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:15.660604Z",
          "start_time": "2025-12-22T09:47:12.845039Z"
        },
        "id": "3155ff43ae4da5d5"
      },
      "cell_type": "code",
      "source": [
        "before_u = len(df_clean)\n",
        "\n",
        "# removing duplicates\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "\n",
        "after_u = len(df_clean)\n",
        "removed_u = before_u - after_u\n",
        "\n",
        "if removed_u > 0:\n",
        "    add_cleaning_step('step11', 'removed existing duplicates', removed_u, after_u)\n"
      ],
      "id": "3155ff43ae4da5d5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8255cea4501b9261"
      },
      "cell_type": "markdown",
      "source": [
        "### step12: final checks and validation"
      ],
      "id": "8255cea4501b9261"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:16.602427Z",
          "start_time": "2025-12-22T09:47:15.906812Z"
        },
        "id": "13c74275e23f2829"
      },
      "cell_type": "code",
      "source": [
        "# checking for null values\n",
        "null_check = df_clean.isnull().sum()\n",
        "print(f\"null count: {null_check}\")"
      ],
      "id": "13c74275e23f2829",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:16.681927Z",
          "start_time": "2025-12-22T09:47:16.659525Z"
        },
        "id": "eb107e6e5a83f439"
      },
      "cell_type": "code",
      "source": [
        "# checking for negative values\n",
        "negative_qty = (df_clean['Quantity'] < 0).sum()\n",
        "negative_price = (df_clean['Price'] <= 0).sum()\n",
        "print(negative_qty, negative_price)"
      ],
      "id": "eb107e6e5a83f439",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:17.065230Z",
          "start_time": "2025-12-22T09:47:16.729440Z"
        },
        "id": "fd6f77cda17c4ed2"
      },
      "cell_type": "code",
      "source": [
        "# final stats\n",
        "print(f\"number of records: {len(df_clean)}\")\n",
        "print(f\"number of unique customers: {df_clean['Customer ID'].nunique()}\")\n",
        "print(f\"number of unique products: {df_clean['StockCode'].nunique()}\")\n",
        "print(f\"number of unique invoices: {df_clean['Invoice'].nunique()}\")\n",
        "print(f\"date range: {df_clean['InvoiceDate'].min()} -> {df_clean['InvoiceDate'].max()}\")"
      ],
      "id": "fd6f77cda17c4ed2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:17.422992Z",
          "start_time": "2025-12-22T09:47:17.089668Z"
        },
        "id": "6bc1d4a95a727e36"
      },
      "cell_type": "code",
      "source": [
        "# key stats\n",
        "print(\"\\nQuantity\")\n",
        "print(df_clean['Quantity'].describe())\n",
        "print(\"\\nPrice\")\n",
        "print(df_clean['Price'].describe())\n",
        "print(\"\\nTotalPrice\")\n",
        "print(df_clean['TotalPrice'].describe())"
      ],
      "id": "6bc1d4a95a727e36",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c71401b20ca2c1a5"
      },
      "cell_type": "markdown",
      "source": [
        "### step13: documenting cleaning report"
      ],
      "id": "c71401b20ca2c1a5"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:47:17.472500Z",
          "start_time": "2025-12-22T09:47:17.450440Z"
        },
        "id": "d00f5d5c98075a7d"
      },
      "cell_type": "code",
      "source": [
        "cleaning_df = pd.DataFrame(cleaning_report)\n",
        "\n",
        "total_removed = df.shape[0] - df_clean.shape[0]\n",
        "removal_percentage = (total_removed / df.shape[0]) * 100\n",
        "\n",
        "print(cleaning_df.to_string(index=False))\n",
        "print(f\"\\nnumber of initial records: {df.shape[0]}\")\n",
        "print(f\"number of final records: {df_clean.shape[0]}\")\n",
        "print(f\"total of removed records: {total_removed} ({removal_percentage:.1f}%)\")\n",
        "print(f\"total of kept records: {df_clean.shape[0]} ({100 - removal_percentage:.1f}%)\")"
      ],
      "id": "d00f5d5c98075a7d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "5f2a6e5e8343d24c"
      },
      "cell_type": "markdown",
      "source": [
        "### step14: exporting the cleaned data"
      ],
      "id": "5f2a6e5e8343d24c"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:48:09.609784Z",
          "start_time": "2025-12-22T09:47:17.569894Z"
        },
        "id": "6e854b1a8ac7949b"
      },
      "cell_type": "code",
      "source": [
        "# saving cleaned data to csv\n",
        "df_clean.to_csv('online_retail_cleaned.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "# for faster importing\n",
        "df_clean.to_pickle('online_retail_cleaned.pkl')"
      ],
      "id": "6e854b1a8ac7949b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4ee4130acd62b64d"
      },
      "cell_type": "markdown",
      "source": [
        "### step15: validation charts"
      ],
      "id": "4ee4130acd62b64d"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:48:23.354975Z",
          "start_time": "2025-12-22T09:48:09.862643Z"
        },
        "id": "5e474f0dd98e529b"
      },
      "cell_type": "code",
      "source": [
        "# validating if the extreme outliers are deleted, negative values exist and if the distrobution is normal and logical\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16,12))\n",
        "fig.suptitle('Data Cleaning Validation Charts', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1) Quantity distrobution chart\n",
        "ax1 = axes[0, 0]\n",
        "ax1.hist(df_clean['Quantity'], bins=50, edgecolor='black', alpha=0.7)\n",
        "ax1.set_xlabel('Quantity', fontsize=12)\n",
        "ax1.set_ylabel('Frequency', fontsize=12)\n",
        "ax1.set_title('Distribution of Quantity (After Cleaning)', fontsize=14, fontweight='bold')\n",
        "ax1.axvline(df_clean['Quantity'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df_clean[\"Quantity\"].mean():.2f}')\n",
        "ax1.axvline(df_clean['Quantity'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df_clean[\"Quantity\"].median():.2f}')\n",
        "ax1.legend(loc='lower right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# adding inset to box plot\n",
        "axins1 = inset_axes(ax1, width=\"40%\", height=\"30%\", loc='upper right')\n",
        "axins1.boxplot(df_clean['Quantity'], vert=False)\n",
        "axins1.set_xlabel('Quantity', fontsize=8)\n",
        "axins1.set_title('Box Plot', fontsize=9)\n",
        "\n",
        "\n",
        "# Price distrobution chart\n",
        "ax2 = axes[0, 1]\n",
        "ax2.hist(df_clean['Price'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "ax2.set_xlabel('Price (£)', fontsize=12)\n",
        "ax2.set_ylabel('Frequency', fontsize=12)\n",
        "ax2.set_title('Distribution of Price (After Cleaning)', fontsize=14, fontweight='bold')\n",
        "ax2.axvline(df_clean['Price'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: £{df_clean[\"Price\"].mean():.2f}')\n",
        "ax2.axvline(df_clean['Price'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: £{df_clean[\"Price\"].median():.2f}')\n",
        "ax2.legend(loc='lower right')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# TotalPrice distrobution chart\n",
        "ax3 = axes[1, 0]\n",
        "total_price_99 = df_clean['TotalPrice'].quantile(0.99)\n",
        "df_plot = df_clean[df_clean['TotalPrice'] <= total_price_99]\n",
        "ax3.hist(df_plot['TotalPrice'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
        "ax3.set_xlabel('TotalPrice (£)', fontsize=12)\n",
        "ax3.set_ylabel('Frequency', fontsize=12)\n",
        "ax3.set_title(f'Distribution of TotalPrice (up to 99th percentile: £{total_price_99:.2f})', fontsize=14, fontweight='bold')\n",
        "ax3.axvline(df_clean['TotalPrice'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: £{df_clean[\"TotalPrice\"].mean():.2f}')\n",
        "ax3.axvline(df_clean['TotalPrice'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: £{df_clean[\"TotalPrice\"].median():.2f}')\n",
        "ax3.legend(loc='lower right')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# number of transactions in time chart\n",
        "ax4 = axes[1, 1]\n",
        "daily_transactions = df_clean.groupby(df_clean['InvoiceDate'].dt.date).size()\n",
        "ax4.plot(daily_transactions.index, daily_transactions.values, linewidth=1, color='purple')\n",
        "ax4.set_xlabel('Date', fontsize=12)\n",
        "ax4.set_ylabel('Number of Transactions', fontsize=12)\n",
        "ax4.set_title('Transactions Over Time (Daily)', fontsize=14, fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# rotating the x axes\n",
        "for label in ax4.get_xticklabels():\n",
        "    label.set_rotation(45)\n",
        "    label.set_ha('right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the charts\n",
        "chart_filename = 'data_cleaning_validation.png'\n",
        "plt.savefig(chart_filename, dpi=300, bbox_inches='tight')"
      ],
      "id": "5e474f0dd98e529b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "62f5d35236e2ccb3"
      },
      "cell_type": "markdown",
      "source": [
        "### step16: final validation test"
      ],
      "id": "62f5d35236e2ccb3"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:48:24.448323Z",
          "start_time": "2025-12-22T09:48:24.263175Z"
        },
        "id": "9f87a7c08dc56eb4"
      },
      "cell_type": "code",
      "source": [
        "# Final validation Tests\n",
        "\n",
        "# list of tests\n",
        "tests_passed = []\n",
        "tests_failed = []\n",
        "\n",
        "# TEST: no nulls in customer id\n",
        "test_1 = 'no NULLs in customer id'\n",
        "try:\n",
        "    assert df_clean['Customer ID'].isna().sum() == 0, \"customer id contains nulls!\"\n",
        "    tests_passed.append(test_1)\n",
        "    print(f\"✓ PASS: {test_1}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_1, str(e)))\n",
        "    print(f\"✗ FAIL: {test_1} - {e}\")\n",
        "\n",
        "\n",
        "# TEST: no negatives in quantity\n",
        "test_2 = 'no negative quantity'\n",
        "try:\n",
        "    assert (df_clean['Quantity'] < 0).sum() == 0, \"negative quantity found!\"\n",
        "    tests_passed.append(test_2)\n",
        "    print(f\"✓ PASS: {test_2}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_2, str(e)))\n",
        "    print(f\"✗ FAIL: {test_2} - {e}\")\n",
        "\n",
        "# TEST: no negatives or zero prices\n",
        "test_3 = 'no negative or zero prices'\n",
        "try:\n",
        "    assert (df_clean['Quantity'] < 0).sum() == 0, \"negative quantity found!\"\n",
        "    tests_passed.append(test_3)\n",
        "    print(f\"✓ PASS: {test_3}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_3, str(e)))\n",
        "    print(f\"✗ FAIL: {test_3} - {e}\")\n",
        "\n",
        "# TEST: TotalPrice calculated correctly\n",
        "test_4 = 'correct total price'\n",
        "try:\n",
        "    assert (df_clean['Quantity'] < 0).sum() == 0, \"negative quantity found!\"\n",
        "    tests_passed.append(test_4)\n",
        "    print(f\"✓ PASS: {test_4}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_4, str(e)))\n",
        "    print(f\"✗ FAIL: {test_4} - {e}\")\n",
        "\n",
        "# TEST: no complete duplicates\n",
        "test_5 = 'no complete duplicates'\n",
        "try:\n",
        "    assert (df_clean['Quantity'] < 0).sum() == 0, \"negative quantity found!\"\n",
        "    tests_passed.append(test_5)\n",
        "    print(f\"✓ PASS: {test_5}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_5, str(e)))\n",
        "    print(f\"✗ FAIL: {test_5} - {e}\")\n",
        "\n",
        "# TEST: quantity in accepted range\n",
        "test_6 = 'quantity in accepted range'\n",
        "try:\n",
        "    assert df_clean['Quantity'].min() >= 1, f\"minimum quantity is {df_clean['Quantity'].min()}\"\n",
        "    assert df_clean['Quantity'].max() <= 10000, f\"maximum quantity is {df_clean['Quantity'].max()}\"\n",
        "    tests_passed.append(test_6)\n",
        "    print(f\"✓ PASS: {test_6}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_6, str(e)))\n",
        "    print(f\"✗ FAIL: {test_6} - {e}\")\n",
        "\n",
        "# TEST: invoice in accepted range\n",
        "test_7 = 'invoice in accepted range'\n",
        "try:\n",
        "    min_date = df_clean['InvoiceDate'].min()\n",
        "    max_date = df_clean['InvoiceDate'].max()\n",
        "    assert min_date >= pd.Timestamp('2009-01-01'), f\"Earliest date {min_date} is before 2009\"\n",
        "    assert max_date <= pd.Timestamp('2012-01-01'), f\"Latest date {max_date} is after 2011\"\n",
        "    tests_passed.append(test_7)\n",
        "    print(f\"✓ PASS: {test_7}\")\n",
        "except AssertionError as e:\n",
        "    tests_failed.append((test_7, str(e)))\n",
        "    print(f\"✗ FAIL: {test_7} - {e}\")"
      ],
      "id": "9f87a7c08dc56eb4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T09:48:24.757712Z",
          "start_time": "2025-12-22T09:48:24.726775Z"
        },
        "id": "aa07b3106a4cc165"
      },
      "cell_type": "code",
      "source": [
        "# overall tests review\n",
        "if tests_failed:\n",
        "    print(f\"Number of Failed Tests: {len(tests_failed)}\")\n",
        "    print(f\"\\nFailed Tests:\")\n",
        "    for test, error in tests_failed:\n",
        "        print(f\"test: {test}, error: {error}\")\n",
        "else:\n",
        "    print(\"ALL TESTS PASSED\")"
      ],
      "id": "aa07b3106a4cc165",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "358c01e55fe70a07"
      },
      "cell_type": "markdown",
      "source": [
        "## Checking Metrics for EDA"
      ],
      "id": "358c01e55fe70a07"
    },
    {
      "metadata": {
        "id": "7526c197aaeb72b5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Loading the Cleaned DataFrame\n",
        "df = pd.read_pickle('online_retail_cleaned.pkl')\n",
        "\n",
        "# Calculating the invoice_level metrics\n",
        "invoice_metrics = df.groupby('Invoice').agg({\n",
        "    'TotalPrice': 'sum',\n",
        "    'Quantity': 'sum'\n",
        "})"
      ],
      "id": "7526c197aaeb72b5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}